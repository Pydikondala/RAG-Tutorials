{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "4124f622",
      "metadata": {
        "id": "4124f622"
      },
      "source": [
        "### Agentic RAG With LangGraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "7309ffec",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "7309ffec",
        "outputId": "0f620963-c7b4-4772-82d1-fa1f09c396bf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.12/dist-packages (1.2.10)\n",
            "Requirement already satisfied: langgraph in /usr/local/lib/python3.12/dist-packages (1.0.8)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.12/dist-packages (1.1.10)\n",
            "Requirement already satisfied: langchain_community in /usr/local/lib/python3.12/dist-packages (0.4.1)\n",
            "Requirement already satisfied: langchain_text_splitters in /usr/local/lib/python3.12/dist-packages (1.1.1)\n",
            "Requirement already satisfied: langchain_core in /usr/local/lib/python3.12/dist-packages (1.2.13)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.12/dist-packages (from langchain) (2.12.3)\n",
            "Requirement already satisfied: langgraph-checkpoint<5.0.0,>=2.1.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (4.0.0)\n",
            "Requirement already satisfied: langgraph-prebuilt<1.1.0,>=1.0.7 in /usr/local/lib/python3.12/dist-packages (from langgraph) (1.0.7)\n",
            "Requirement already satisfied: langgraph-sdk<0.4.0,>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (0.3.6)\n",
            "Requirement already satisfied: xxhash>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from langgraph) (3.6.0)\n",
            "Requirement already satisfied: openai<3.0.0,>=2.20.0 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (2.21.0)\n",
            "Requirement already satisfied: tiktoken<1.0.0,>=0.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain_openai) (0.12.0)\n",
            "Requirement already satisfied: langchain-classic<2.0.0,>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (1.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3.0.0,>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.46)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.5 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.32.5)\n",
            "Requirement already satisfied: PyYAML<7.0.0,>=5.3.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (6.0.3)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (3.13.3)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (9.1.4)\n",
            "Requirement already satisfied: dataclasses-json<0.7.0,>=0.6.7 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.6.7)\n",
            "Requirement already satisfied: pydantic-settings<3.0.0,>=2.10.1 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.13.0)\n",
            "Requirement already satisfied: langsmith<1.0.0,>=0.1.125 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.7.3)\n",
            "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (0.4.3)\n",
            "Requirement already satisfied: numpy>=1.26.2 in /usr/local/lib/python3.12/dist-packages (from langchain_community) (2.0.2)\n",
            "Requirement already satisfied: jsonpatch<2.0.0,>=1.33.0 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (1.33)\n",
            "Requirement already satisfied: packaging>=23.2.0 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (26.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.7.0 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (4.15.0)\n",
            "Requirement already satisfied: uuid-utils<1.0,>=0.12.0 in /usr/local/lib/python3.12/dist-packages (from langchain_core) (0.14.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.7.1)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.22.0)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (3.26.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.12/dist-packages (from dataclasses-json<0.7.0,>=0.6.7->langchain_community) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.12/dist-packages (from jsonpatch<2.0.0,>=1.33.0->langchain_core) (3.0.0)\n",
            "Requirement already satisfied: ormsgpack>=1.12.0 in /usr/local/lib/python3.12/dist-packages (from langgraph-checkpoint<5.0.0,>=2.1.0->langgraph) (1.12.2)\n",
            "Requirement already satisfied: httpx>=0.25.2 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.28.1)\n",
            "Requirement already satisfied: orjson>=3.10.1 in /usr/local/lib/python3.12/dist-packages (from langgraph-sdk<0.4.0,>=0.3.0->langgraph) (3.11.7)\n",
            "Requirement already satisfied: requests-toolbelt>=1.0.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (1.0.0)\n",
            "Requirement already satisfied: zstandard>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from langsmith<1.0.0,>=0.1.125->langchain_community) (0.25.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain_openai) (4.12.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain_openai) (1.9.0)\n",
            "Requirement already satisfied: jiter<1,>=0.10.0 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain_openai) (0.13.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.12/dist-packages (from openai<3.0.0,>=2.20.0->langchain_openai) (4.67.3)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.41.4 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.41.4)\n",
            "Requirement already satisfied: typing-inspection>=0.4.2 in /usr/local/lib/python3.12/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.2)\n",
            "Requirement already satisfied: python-dotenv>=0.21.0 in /usr/local/lib/python3.12/dist-packages (from pydantic-settings<3.0.0,>=2.10.1->langchain_community) (1.2.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests<3.0.0,>=2.32.5->langchain_community) (2026.1.4)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.12/dist-packages (from SQLAlchemy<3.0.0,>=1.4.0->langchain_community) (3.3.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.12/dist-packages (from tiktoken<1.0.0,>=0.7.0->langchain_openai) (2025.11.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.25.2->langgraph-sdk<0.4.0,>=0.3.0->langgraph) (0.16.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.12/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.7->langchain_community) (1.1.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain langgraph langchain_openai langchain_community langchain_text_splitters langchain_core\n",
        "import os\n",
        "from typing import TypedDict, List\n",
        "from langgraph.graph import StateGraph, END\n",
        "from langchain_openai import ChatOpenAI, OpenAIEmbeddings\n",
        "from langchain_community.vectorstores import FAISS\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter\n",
        "from langchain_core.documents import Document"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "733dbdd0",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "733dbdd0",
        "outputId": "7374fd45-706a-4abc-dc36-4684bde3ec1c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "3675ecda",
      "metadata": {
        "id": "3675ecda"
      },
      "outputs": [],
      "source": [
        "# Set your OpenAI API key\n",
        "# Replace 'YOUR_OPENAI_API_KEY' with your actual OpenAI API key\n",
        "os.environ[\"OPENAI_API_KEY\"] = os.getenv(\"OPENAI_API_KEY\")\n",
        "\n",
        "# Initialize models\n",
        "llm = ChatOpenAI(model=\"gpt-3.5-turbo\", temperature=0)\n",
        "embeddings = OpenAIEmbeddings()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f5a3353",
      "metadata": {
        "id": "7f5a3353",
        "outputId": "71065e14-fb3e-4b82-8000-524e33cfe16b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "ChatOpenAI(client=<openai.resources.chat.completions.completions.Completions object at 0x000001C7CF964B90>, async_client=<openai.resources.chat.completions.completions.AsyncCompletions object at 0x000001C7CF9651D0>, root_client=<openai.OpenAI object at 0x000001C7D039DE50>, root_async_client=<openai.AsyncOpenAI object at 0x000001C7CF964E10>, model_name='gpt-4.1', temperature=0.0, model_kwargs={}, openai_api_key=SecretStr('**********'))"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "llm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7424db63",
      "metadata": {
        "id": "7424db63"
      },
      "source": [
        "## State Definition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "59befbc8",
      "metadata": {
        "id": "59befbc8"
      },
      "outputs": [],
      "source": [
        "class AgentState(TypedDict):\n",
        "    question: str\n",
        "    documents: List[Document]\n",
        "    answer: str\n",
        "    needs_retrieval: bool"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "uPUVix2DqzWH"
      },
      "id": "uPUVix2DqzWH"
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "id": "ad06275d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 426
        },
        "collapsed": true,
        "id": "ad06275d",
        "outputId": "6160ec33-25d9-40ba-b81a-1c89a249ce0a"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "AuthenticationError",
          "evalue": "Error code: 401 - {'error': {'message': 'Incorrect API key provided: YOUR_OPE*******_KEY. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAuthenticationError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-563/3176665346.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m##create vector store\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mvectorstore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdocuments\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mretriever\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvectorstore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_retriever\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_core/vectorstores/base.py\u001b[0m in \u001b[0;36mfrom_documents\u001b[0;34m(cls, documents, embedding, **kwargs)\u001b[0m\n\u001b[1;32m    812\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"ids\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mids\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    813\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 814\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetadatas\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetadatas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    815\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mclassmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_community/vectorstores/faiss.py\u001b[0m in \u001b[0;36mfrom_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, **kwargs)\u001b[0m\n\u001b[1;32m   1041\u001b[0m                 \u001b[0mfaiss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFAISS\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1042\u001b[0m         \"\"\"\n\u001b[0;32m-> 1043\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membed_documents\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtexts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1044\u001b[0m         return cls.__from(\n\u001b[1;32m   1045\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/embeddings/base.py\u001b[0m in \u001b[0;36membed_documents\u001b[0;34m(self, texts, chunk_size, **kwargs)\u001b[0m\n\u001b[1;32m    749\u001b[0m         \u001b[0;31m# This could be optimized to avoid double work when all texts are short enough.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m         \u001b[0mengine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeployment\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m         return self._get_len_safe_embeddings(\n\u001b[0m\u001b[1;32m    752\u001b[0m             \u001b[0mtexts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunk_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mchunk_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         )\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/langchain_openai/embeddings/base.py\u001b[0m in \u001b[0;36m_get_len_safe_embeddings\u001b[0;34m(self, texts, engine, chunk_size, **kwargs)\u001b[0m\n\u001b[1;32m    616\u001b[0m             \u001b[0;31m# Make API call with this batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m             \u001b[0mbatch_tokens\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokens\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mbatch_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_tokens\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mclient_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m                 \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel_dump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/resources/embeddings.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, input, model, dimensions, encoding_format, user, extra_headers, extra_query, extra_body, timeout)\u001b[0m\n\u001b[1;32m    130\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m         return self._post(\n\u001b[0m\u001b[1;32m    133\u001b[0m             \u001b[0;34m\"/embeddings\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m             \u001b[0mbody\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmaybe_transform\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_create_params\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mEmbeddingCreateParams\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mpost\u001b[0;34m(self, path, cast_to, body, content, options, files, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1295\u001b[0m             \u001b[0mmethod\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"post\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0murl\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcontent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiles\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mto_httpx_files\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiles\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1296\u001b[0m         )\n\u001b[0;32m-> 1297\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcast\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mResponseT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequest\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcast_to\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream_cls\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream_cls\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1299\u001b[0m     def patch(\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/openai/_base_client.py\u001b[0m in \u001b[0;36mrequest\u001b[0;34m(self, cast_to, options, stream, stream_cls)\u001b[0m\n\u001b[1;32m   1068\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1069\u001b[0m                 \u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdebug\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Re-raising status error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1070\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_status_error_from_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1071\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1072\u001b[0m             \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAuthenticationError\u001b[0m: Error code: 401 - {'error': {'message': 'Incorrect API key provided: YOUR_OPE*******_KEY. You can find your API key at https://platform.openai.com/account/api-keys.', 'type': 'invalid_request_error', 'param': None, 'code': 'invalid_api_key'}}"
          ]
        }
      ],
      "source": [
        "### Sample Docuemnt And VectorStore\n",
        "# Sample documents for demonstration\n",
        "sample_texts = [\n",
        "    \"LangGraph is a library for building stateful, multi-actor applications with LLMs. It extends LangChain with the ability to coordinate multiple chains across multiple steps of computation in a cyclic manner.\",\n",
        "    \"RAG (Retrieval-Augmented Generation) is a technique that combines information retrieval with text generation. It retrieves relevant documents and uses them to provide context for generating more accurate responses.\",\n",
        "    \"Vector databases store high-dimensional vectors and enable efficient similarity search. They are commonly used in RAG systems to find relevant documents based on semantic similarity.\",\n",
        "    \"Agentic systems are AI systems that can take actions, make decisions, and interact with their environment autonomously. They often use planning and reasoning capabilities.\"\n",
        "]\n",
        "\n",
        "documents=[Document(page_content=text) for text in sample_texts]\n",
        "\n",
        "##create vector store\n",
        "vectorstore = FAISS.from_documents(documents, embeddings)\n",
        "retriever = vectorstore.as_retriever(k=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "514f94c2",
      "metadata": {
        "id": "514f94c2"
      },
      "source": [
        "### Agents function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8586493c",
      "metadata": {
        "id": "8586493c"
      },
      "outputs": [],
      "source": [
        "def decide_retrieval(state: AgentState) -> AgentState:\n",
        "    \"\"\"\n",
        "    Decide if we need to retrieve documents based on the question\n",
        "    \"\"\"\n",
        "    question = state[\"question\"]\n",
        "\n",
        "    # Simple heuristic: if question contains certain keywords, retrieve\n",
        "    retrieval_keywords = [\"what\", \"how\", \"explain\", \"describe\", \"tell me\"]\n",
        "    needs_retrieval = any(keyword in question.lower() for keyword in retrieval_keywords)\n",
        "\n",
        "    return {**state, \"needs_retrieval\": needs_retrieval}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "46abbde1",
      "metadata": {
        "id": "46abbde1"
      },
      "outputs": [],
      "source": [
        "def retrieve_documents(state: AgentState) -> AgentState:\n",
        "    \"\"\"\n",
        "    Retrieve relevant documents based on the question\n",
        "    \"\"\"\n",
        "    question = state[\"question\"]\n",
        "    documents = retriever.invoke(question)\n",
        "\n",
        "    return {**state, \"documents\": documents}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b6d44011",
      "metadata": {
        "id": "b6d44011"
      },
      "outputs": [],
      "source": [
        "def generate_answer(state: AgentState) -> AgentState:\n",
        "    \"\"\"\n",
        "    Generate an answer using the retrieved documents or direct response\n",
        "    \"\"\"\n",
        "    question = state[\"question\"]\n",
        "    documents = state.get(\"documents\", [])\n",
        "\n",
        "    if documents:\n",
        "        # RAG approach: use documents as context\n",
        "        context = \"\\n\\n\".join([doc.page_content for doc in documents])\n",
        "        prompt = f\"\"\"Based on the following context, answer the question:\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question: {question}\n",
        "\n",
        "Answer:\"\"\"\n",
        "    else:\n",
        "        # Direct response without retrieval\n",
        "        prompt = f\"Answer the following question: {question}\"\n",
        "\n",
        "    response = llm.invoke(prompt)\n",
        "    answer = response.content\n",
        "\n",
        "    return {**state, \"answer\": answer}"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "11c2e947",
      "metadata": {
        "id": "11c2e947"
      },
      "source": [
        "### conditional Logic"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b240fb29",
      "metadata": {
        "id": "b240fb29"
      },
      "outputs": [],
      "source": [
        "def should_retrieve(state: AgentState) -> str:\n",
        "    \"\"\"\n",
        "    Determine the next step based on retrieval decision\n",
        "    \"\"\"\n",
        "    if state[\"needs_retrieval\"]:\n",
        "        return \"retrieve\"\n",
        "    else:\n",
        "        return \"generate\""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92f8aa18",
      "metadata": {
        "id": "92f8aa18"
      },
      "source": [
        "### build the Graph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f0ea2c36",
      "metadata": {
        "id": "f0ea2c36",
        "outputId": "25b094ed-2983-4960-d006-4d9ac4392921"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<langgraph.graph.state.CompiledStateGraph object at 0x000001C7CF966490>"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Create the state graph\n",
        "workflow = StateGraph(AgentState)\n",
        "\n",
        "# Add nodes\n",
        "workflow.add_node(\"decide\", decide_retrieval)\n",
        "workflow.add_node(\"retrieve\", retrieve_documents)\n",
        "workflow.add_node(\"generate\", generate_answer)\n",
        "\n",
        "# Set entry point\n",
        "workflow.set_entry_point(\"decide\")\n",
        "\n",
        "# Add conditional edges\n",
        "workflow.add_conditional_edges(\n",
        "    \"decide\",\n",
        "    should_retrieve,\n",
        "    {\n",
        "        \"retrieve\": \"retrieve\",\n",
        "        \"generate\": \"generate\"\n",
        "    }\n",
        ")\n",
        "\n",
        "# Add edges\n",
        "workflow.add_edge(\"retrieve\", \"generate\")\n",
        "workflow.add_edge(\"generate\", END)\n",
        "\n",
        "# Compile the graph\n",
        "app = workflow.compile()\n",
        "app"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bf98bef7",
      "metadata": {
        "id": "bf98bef7"
      },
      "source": [
        "### test the Agentic System"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fe6349f1",
      "metadata": {
        "id": "fe6349f1"
      },
      "outputs": [],
      "source": [
        "def ask_question(question: str):\n",
        "    \"\"\"\n",
        "    Helper function to ask a question and get an answer\n",
        "    \"\"\"\n",
        "    initial_state = {\n",
        "        \"question\": question,\n",
        "        \"documents\": [],\n",
        "        \"answer\": \"\",\n",
        "        \"needs_retrieval\": False\n",
        "    }\n",
        "\n",
        "    result = app.invoke(initial_state)\n",
        "    return result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5d321ee0",
      "metadata": {
        "id": "5d321ee0",
        "outputId": "09f53f89-5bc9-4a0c-bdb0-571bd1a70243"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'question': 'What is LangGraph?',\n",
              " 'documents': [Document(id='30677815-a9f6-4f14-8920-5421b5eefb14', metadata={}, page_content='LangGraph is a library for building stateful, multi-actor applications with LLMs. It extends LangChain with the ability to coordinate multiple chains across multiple steps of computation in a cyclic manner.'),\n",
              "  Document(id='353f0046-6350-426f-b24b-4bfa2a71b093', metadata={}, page_content='RAG (Retrieval-Augmented Generation) is a technique that combines information retrieval with text generation. It retrieves relevant documents and uses them to provide context for generating more accurate responses.'),\n",
              "  Document(id='a9ecfc07-01f0-450e-ac3f-b345ea2528d0', metadata={}, page_content='Vector databases store high-dimensional vectors and enable efficient similarity search. They are commonly used in RAG systems to find relevant documents based on semantic similarity.'),\n",
              "  Document(id='062bcab7-fb6e-422a-9e53-e7e7c5a4304b', metadata={}, page_content='Agentic systems are AI systems that can take actions, make decisions, and interact with their environment autonomously. They often use planning and reasoning capabilities.')],\n",
              " 'answer': 'LangGraph is a library for building stateful, multi-actor applications with large language models (LLMs). It extends LangChain by enabling the coordination of multiple chains (or agents) across multiple steps of computation in a cyclic manner, allowing for more complex workflows and interactions between different components in an application.',\n",
              " 'needs_retrieval': True}"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# Test with a question that should trigger retrieval\n",
        "question1 = \"What is LangGraph?\"\n",
        "result1 = ask_question(question1)\n",
        "result1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34ca35af",
      "metadata": {
        "id": "34ca35af",
        "outputId": "7fa02c85-dff4-48ee-bf5e-0d684c00e591"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Question: How does RAG work?\n",
            "Retrieved documents: 4\n",
            "Answer: RAG (Retrieval-Augmented Generation) works by combining information retrieval with text generation to produce more accurate and contextually relevant responses. Heres how it works:\n",
            "\n",
            "1. **Retrieval Step:**  \n",
            "   When a user asks a question, the system first retrieves relevant documents or passages from a large collection of data. This is often done using a vector database, which stores documents as high-dimensional vectors and enables efficient similarity search based on the semantic meaning of the query.\n",
            "\n",
            "2. **Augmentation Step:**  \n",
            "   The retrieved documents are then used to provide additional context to the language model. This means the model has access to up-to-date or domain-specific information that may not be present in its original training data.\n",
            "\n",
            "3. **Generation Step:**  \n",
            "   The language model (such as an LLM) takes both the users question and the retrieved context to generate a final, informed response. This helps the model produce answers that are more accurate, grounded, and relevant to the users query.\n",
            "\n",
            "In summary, RAG enhances the capabilities of language models by supplementing them with external knowledge retrieved in real time, leading to better and more reliable answers.\n",
            "\n",
            "==================================================\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Test with another question\n",
        "question2 = \"How does RAG work?\"\n",
        "result2 = ask_question(question2)\n",
        "\n",
        "print(f\"Question: {question2}\")\n",
        "print(f\"Retrieved documents: {len(result2['documents'])}\")\n",
        "print(f\"Answer: {result2['answer']}\")\n",
        "print(\"\\n\" + \"=\"*50 + \"\\n\")"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "YTRAG",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.2"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}